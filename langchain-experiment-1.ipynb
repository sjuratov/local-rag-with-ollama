{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.datacamp.com/tutorial/llama-3-1-rag\n",
    "\n",
    "## Prerequisits:\n",
    "- Install [ollama](https://ollama.com/)\n",
    "- Run ollama from terminal: ```ollama run llama3.1```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "AZURE_OPENAI_EMBEDDING_MODEL = os.getenv('AZURE_OPENAI_EMBEDDING_MODEL')\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "AZURE_OPENAI_API_VERSION = os.getenv('AZURE_OPENAI_API_VERSION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# List of URLs to load documents from\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "# Load documents from the URLs\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list = [item for sublist in docs for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize a text splitter with specified chunk size and overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "# Split the documents into chunks\n",
    "doc_splits = text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "# Create embeddings for documents and store them in a vector store\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=AzureOpenAIEmbeddings(\n",
    "        model=AZURE_OPENAI_EMBEDDING_MODEL,\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_key=AZURE_OPENAI_API_KEY,\n",
    "        openai_api_version=AZURE_OPENAI_API_VERSION\n",
    "        )\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is CoT?\"\n",
    "retrieved_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': None,\n",
       " 'metadata': {'id': 'daa40931-65ca-461d-bf9c-e1fbba38f7b6',\n",
       "  'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/',\n",
       "  'title': \"Prompt Engineering | Lil'Log\",\n",
       "  'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models.',\n",
       "  'language': 'en'},\n",
       " 'page_content': 'Two main types of CoT prompting:',\n",
       " 'type': 'Document'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Document 1\n",
       "\n",
       "**Source:** https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\n",
       "\n",
       "**Title:** Prompt Engineering | Lil'Log\n",
       "\n",
       "**Description:** Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\n",
       "This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models.\n",
       "\n",
       "**Language:** en\n",
       "\n",
       "**Content:** Two main types of CoT prompting:\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Document 2\n",
       "\n",
       "**Source:** https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\n",
       "\n",
       "**Title:** Prompt Engineering | Lil'Log\n",
       "\n",
       "**Description:** Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\n",
       "This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models.\n",
       "\n",
       "**Language:** en\n",
       "\n",
       "**Content:** Few-shot CoT. It is to prompt the model with a few demonstrations, each containing manually written (or model-generated) high-quality reasoning chains.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Document 3\n",
       "\n",
       "**Source:** https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\n",
       "\n",
       "**Title:** Prompt Engineering | Lil'Log\n",
       "\n",
       "**Description:** Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\n",
       "This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models.\n",
       "\n",
       "**Language:** en\n",
       "\n",
       "**Content:** Fig. 3. Comparing CoT and PoT. (Image source: Chen et al. 2022).\n",
       "External APIs#\n",
       "TALM (Tool Augmented Language Models; Parisi et al. 2022) is a language model augmented with text-to-text API calls. LM is guided to generate |tool-call and tool input text conditioned on task input text to construct API call requests. When |result shows up, the specified tool API is called and the returned result gets appended to the text sequence. The final output is generated following |output token.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Document 4\n",
       "\n",
       "**Source:** https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\n",
       "\n",
       "**Title:** Prompt Engineering | Lil'Log\n",
       "\n",
       "**Description:** Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\n",
       "This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models.\n",
       "\n",
       "**Language:** en\n",
       "\n",
       "**Content:** Definition: Classify the sentiment of the given movie review, \"positive\" or \"negative\".\n",
       "Input: i'll bet the video game is a lot more fun than the film.\n",
       "Output:\n",
       "Self-Consistency Sampling#\n",
       "Self-consistency sampling (Wang et al. 2022a) is to sample multiple outputs with temperature > 0 and then selecting the best one out of these candidates.\n",
       "The criteria for selecting the best candidate can vary from task to task. A general solution is to pick majority vote. For tasks that are easy to validate such as a programming question with unit tests, we can simply run through the interpreter and verify the correctness with unit tests.\n",
       "Chain-of-Thought (CoT)#\n",
       "Chain-of-thought (CoT) prompting (Wei et al. 2022) generates a sequence of short sentences to describe reasoning logics step by step, known as reasoning chains or rationales, to eventually lead to the final answer. The benefit of CoT is more pronounced for complicated reasoning tasks, while using large models (e.g. with more than 50B parameters). Simple tasks only benefit slightly from CoT prompting.\n",
       "Types of CoT prompts#\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "for indx, doc in enumerate(retrieved_docs, start=1):\n",
    "    md_content = f\"\"\"### Document {indx}\n",
    "\n",
    "**Source:** {doc.metadata['source']}\n",
    "\n",
    "**Title:** {doc.metadata['title']}\n",
    "\n",
    "**Description:** {doc.metadata['description']}\n",
    "\n",
    "**Language:** {doc.metadata['language']}\n",
    "\n",
    "**Content:** {doc.page_content}\n",
    "    \"\"\"\n",
    "    display(Markdown(md_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# Define the prompt template for the LLM\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks.\n",
    "    Use the following documents to answer the question.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    Use three sentences maximum and keep the answer concise:\n",
    "    Question: {question}\n",
    "    Documents: {documents}\n",
    "    Answer:\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM with Llama 3.1 model\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain combining the prompt template and LLM\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RAG application class\n",
    "class RAGApplication:\n",
    "    def __init__(self, retriever, rag_chain):\n",
    "        self.retriever = retriever\n",
    "        self.rag_chain = rag_chain\n",
    "    def run(self, question):\n",
    "        # Retrieve relevant documents\n",
    "        documents = self.retriever.invoke(question)\n",
    "        # Extract content from retrieved documents\n",
    "        doc_texts = \"\\\\n\".join([doc.page_content for doc in documents])\n",
    "        # Get the answer from the language model\n",
    "        answer = self.rag_chain.invoke({\"question\": question, \"documents\": doc_texts})\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is CoT?\n",
      "Answer: Chain-of-Thought (CoT) prompting generates a sequence of short sentences to describe reasoning logics step by step, known as reasoning chains or rationales, to eventually lead to the final answer. This type of prompting is more beneficial for complicated reasoning tasks and uses large models with over 50B parameters. It involves providing a few demonstrations, each containing manually written high-quality reasoning chains.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RAG application\n",
    "rag_application = RAGApplication(retriever, rag_chain)\n",
    "# Example usage\n",
    "question = \"What is CoT?\"\n",
    "answer = rag_application.run(question)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
